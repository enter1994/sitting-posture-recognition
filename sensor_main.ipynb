{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73c98d4b-081f-4e09-8332-e04717b1591f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moon/miniconda3/envs/har/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/moon/miniconda3/envs/har/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/moon/miniconda3/envs/har/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loaded\n",
      "dataloader loaded\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import argparse\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataloader.sensor_loader2 import CustomDataset\n",
    "from src.train_sensor import *\n",
    "\n",
    "# def get_args():\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument('-verbose', default=0, type=int,\n",
    "#                         help=\"Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch. default: 0\")\n",
    "#     parser.add_argument('-model', default='resnet18', help='Choose model type resnet18, resnet34, vgg16')\n",
    "#     parser.add_argument('-epochs', default=5, type=int, help=\"Number of epoch to train. default: 5\")\n",
    "#     parser.add_argument('-batch_size', default=1, type=int, help=\"Number of samples per gradient update. default: 1\")\n",
    "#     parser.add_argument('-lr', '--learning_rate', type=float, default=1e-3, help='Set learning rate')\n",
    "#     parser.add_argument('-chkt_filename', default='./weights', help=\"Model Checkpoint filename to save.\")\n",
    "#     parser.add_argument('-t', '--fine_tunning_interval', default=1, type=int, help=\"Fine-tuning interval. default: 1\")\n",
    "#     parser.add_argument('-gn','--gpu_number', default=0, type=int,\n",
    "#                         help='Number of GPU. default: 0')\n",
    "#     parser.add_argument('-vdp', '--video_data_path', default='./Large_Captcha_Dataset',\n",
    "#                         help=\"Location of video dataset. default: \\'./Large_Captcha_Dataset\\'\")\n",
    "#     parser.add_argument('-sdp', '--sensor_data_path', default='./Large_Captcha_Dataset',\n",
    "#                         help=\"Location of sensor dataset. default: \\'./Large_Captcha_Dataset\\'\")\n",
    "#     parser.add_argument('-wandb', default=False, action=\"store_true\",\n",
    "#                         help=\"Do you wanna use wandb? just give it True! default:False\")\n",
    "#     parser.add_argument('-pn', '--project_name', required=True,\n",
    "#                         help=\"Set wandb project name\")\n",
    "#     args = parser.parse_args()\n",
    "    \n",
    "#     return args\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # args = get_args()\n",
    "    # experiment=None\n",
    "\n",
    "#     if args.wandb:\n",
    "#         experiment = wandb.init(\n",
    "#             project=args.project_name, entity='captcha-active-learning-jinro', config={\n",
    "#                 'model' : args.model,\n",
    "#                 'learning_rate' : args.learning_rate,\n",
    "#                 'epochs' : args.epochs,\n",
    "#                 'batch_size' : args.batch_size,})\n",
    "\n",
    "#     print(json.dumps({\n",
    "#         \"model\" : args.model,\n",
    "#         \"learning_rate\": args.learning_rate,\n",
    "#         \"epochs\": args.epochs,\n",
    "#         \"batch_size\": args.batch_size\n",
    "#     }, indent=4))\n",
    "    device = f'cuda:{1}'\n",
    "    \n",
    "    mmodel = 'resnet18'\n",
    "    args = None\n",
    "    fcl = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.Linear(128, 6))\n",
    "    \n",
    "    if mmodel == 'resnet18':\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        model.fc = fcl\n",
    "    elif mmodel == 'resnet34':\n",
    "        model = models.resnet32(pretrained=True)\n",
    "        model.fc = fcl\n",
    "    elif mmodel == 'vgg16':\n",
    "        model = models.vgg16(pretrained=True)\n",
    "        avgpool = nn.AdaptiveAvgPool2d(output_size = (1,1))\n",
    "        model.avgpool = avgpool\n",
    "        model.classifier = fcl\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    train_dataset = CustomDataset(mode='Train')\n",
    "    test_dataset = CustomDataset(mode='Test')\n",
    "    print('dataset loaded')\n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "    test_dataloader  = DataLoader(test_dataset, batch_size=1)\n",
    "    print('dataloader loaded')\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "    loss_fn.to(device)\n",
    "\n",
    "    \n",
    "    \n",
    "#     for epoch in tqdm(range(20)):\n",
    "#         print(f'Epoch : {epoch+1} \\n--------------------------------')\n",
    "\n",
    "#         train_sensor(args, experiment, model, train_dataloader, loss_fn, optimizer, device)\n",
    "#         test_sensor(args, experiment, model, test_dataloader, loss_fn, optimizer, device)\n",
    "\n",
    "#     print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "068c900c-a2cd-494d-858b-7b4563bf39ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/moon/datasets/sitting-posture-recognition/3D_img_small/Train/A2_재영_2_1.jpg\n",
      "(288, 432, 3)\n",
      "(3, 224, 224)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       " \n",
       "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       " \n",
       "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]]]]),\n",
       " tensor([2])]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61d7ecf3-cd45-43d3-9ba9-590b56da55ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'o'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mCustomDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/research/sitting-posture-recognition/dataloader/sensor_loader2.py:44\u001b[0m, in \u001b[0;36mCustomDataset.__init__\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m     41\u001b[0m     category \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(name)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel\u001b[38;5;241m.\u001b[39mappend(category)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;28mstr\u001b[39m(name), \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcategory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'o'"
     ]
    }
   ],
   "source": [
    "CustomDataset(mode='Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d0d33b8-eb89-46c0-842c-34b8ce555cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a78aff0-2371-483b-8e1f-f143fe76a388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/moon/datasets/sitting-posture-recognition/3D_img_small/Train/A2_정현_2_5.jpg\n",
      "['', 'data', 'moon', 'datasets', 'sitting-posture-recognition', '3D_img_small', 'Train', 'A2_정현_2_5']\n",
      "moon\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'o'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(category)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# self.label.append(category)\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28mprint\u001b[39m((\u001b[38;5;28mstr\u001b[39m(name), \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcategory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m))\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'o'"
     ]
    }
   ],
   "source": [
    " for name in pathlib.Path(f'/data/moon/datasets/sitting-posture-recognition/3D_img_small/Train/').glob('*.jpg'):\n",
    "        print(str(name).encode('utf-8').decode('utf-8'))\n",
    "        # print(os.path.splitext(name)[0].split('/')[-1].split('_')[0][1])\n",
    "        print(os.path.splitext(name)[0].split('/'))\n",
    "        category = os.path.splitext(name)[0].split('/')[2]\n",
    "        print(category)\n",
    "        # self.label.append(category)\n",
    "\n",
    "        print((str(name), int(category[1])))\n",
    "        # self.data = sorted(self.data)\n",
    "        # print(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a64142-cfb8-4847-8993-d9f71f43ecd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "har",
   "language": "python",
   "name": "har"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
